{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data Augmentation\n",
    "\n",
    "Às vezes, o aprendizado de máquina (ML) se depara com um problema em que os dados de treinamento têm tamanho limitado e com menos dados, o modelo de ML falha em capturar variação suficiente. Para tornar nosso modelo generalizado bem em dados novos ou invisíveis, precisamos ter mais dados. Para atenuar esse problema, podemos obter ajuda de __Data Augmentation__.\n",
    "\n",
    "![](dandelion.jpg)\n",
    "\n",
    "### O que é Data Augmentation?\n",
    "\n",
    "Data augmentation (aumento de dados) significa simplesmente aumentar o número de pontos de dados. Por exemplo, na visão computacional, geramos mais imagens a partir das imagens já fornecidas, com a ajuda de vários métodos, como rotação de imagem, alteração das condições de iluminação, corte de imagem etc.\n",
    "\n",
    "### Por que usar augment em dados textuais?\n",
    "\n",
    "A maioria dos problemas da NLP é resolvida aplicando um modelo de machine learning ou deep learning nos dados de texto pré-processados. Portanto, faz sentido aumentar e gerar mais dados de texto. Uma solução poderia ser a de coletar mais dados, mas isso teria um custo que pode ser em termos de dinheiro, esforço humano e tempo fora do curso consumido no processo. Portanto, __data augmentation de texto__ é uma alternativa melhor nesses casos.\n",
    "\n",
    "Neste notebook, usaremos as três abordagens a seguir para criar dados de texto aumentados (augmentation):\n",
    "\n",
    "1. Tire as palavras aleatoriamente\n",
    "2. Concatenar POS tags para texto\n",
    "3. Substitua as entidades nomeadas por suas categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy # uma das utilizações usando spacy é data augmentation\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será usado o modelo para português do spaCy neste notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para baixar o módulo para português\n",
    "- Colocar na linha de comando dentro do environment\n",
    "    - python -m spacy download pt_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pt_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trabalharemos com o texto de exemplo a seguir ao longo deste exercício."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Eu visitei este lugar no dia dos namorados à noite. Tivemos que esperar cerca de 15 minutos para conseguir uma mesa aqui. Utilizamos esse tempo para tirar fotos;) Este lugar tinha uma vibração muito fria com música alta ao fundo. A transmissão ao vivo de uma partida de críquete também estava acontecendo. Foi um pouco difícil manter uma conversa com alguém.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tirar as palavras aleatoriamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta abordagem, tentaremos gerar várias versões do texto de amostra, omitindo algumas palavras aleatoriamente do texto. Por exemplo, considere esta frase \"Aumentar pequenos conjuntos de dados é importante e desafiador\". Suas versões aumentadas seriam como ...\n",
    "\n",
    "* Aumentar conjuntos de dados é um desafio importante\n",
    "* Aumentar pequenos conjuntos de dados importantes e\n",
    "* pequeno é importante e desafiador\n",
    "\n",
    "Portanto, a ideia é bastante simples, mas bastante eficaz. Seguiremos os passos abaixo:\n",
    "\n",
    "1. Tokenize o texto de amostra\n",
    "2. Encontre o número de tokens\n",
    "3. Defina a porcentagem de palavras a serem mantidas\n",
    "4. Omita aleatoriamente as palavras para gerar novos dados de texto\n",
    "\n",
    "Soa interessante? Vamos começar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenização\n",
    "tokens = []\n",
    "for token in doc:\n",
    "    tokens.append(token.text)\n",
    "    \n",
    "# encontrar o nro de tokens\n",
    "l = len(tokens)\n",
    "\n",
    "# nro de tokens recuperados\n",
    "random_tokens_count = round(0.8*l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geraremos 5 versões de texto aumentado. Sinta-se à vontade para gerar quantas versões desejar, alterando o valor de ___n___."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista para armazenar augmentation sobre o texto\n",
    "augmented_texts = []\n",
    "\n",
    "# nro de versões\n",
    "n = 5\n",
    "\n",
    "for i in range(n):\n",
    "    # randomicamente gerar índices de tokens\n",
    "    new_tokens_index = random.sample(range(l), random_tokens_count)\n",
    "    new_tokens_index.sort()\n",
    "    \n",
    "    # gerar augmentation na lista de tokens\n",
    "    new_tokens = [tokens[t] for t in new_tokens_index]\n",
    "    \n",
    "    # criar augmentation\n",
    "    augmented_texts.append(' '.join(new_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificar o texto após o aumento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visitei este lugar no dia dos namorados à . Tivemos que esperar cerca 15 para conseguir uma aqui . Utilizamos esse tempo tirar fotos ) Este lugar tinha uma vibração muito fria com música alta a o fundo . A transmissão a de uma partida de críquete estava acontecendo Foi um pouco uma com alguém .\n",
      "\n",
      "Eu este lugar no dos namorados à noite Tivemos que esperar cerca de 15 minutos para conseguir uma mesa aqui Utilizamos esse para tirar ) tinha uma vibração muito fria com música alta o fundo A a o vivo de partida de críquete também estava acontecendo . Foi um pouco difícil manter uma com alguém .\n",
      "\n",
      "Eu visitei este lugar dia dos namorados à noite Tivemos que esperar cerca de 15 minutos para conseguir uma mesa aqui . esse tempo tirar ; Este tinha uma vibração fria com música alta a o fundo . transmissão a vivo uma partida de críquete também estava um pouco difícil manter uma conversa com alguém .\n",
      "\n",
      "Eu este no dia dos namorados à . Tivemos que de minutos para conseguir uma mesa aqui . Utilizamos esse tempo para tirar ) Este lugar tinha uma muito fria com música alta o fundo . A transmissão a o de partida de críquete também estava acontecendo . Foi pouco difícil manter conversa com alguém .\n",
      "\n",
      "Eu visitei este lugar dia dos namorados noite . Tivemos que esperar cerca de para conseguir uma mesa Utilizamos tempo para tirar fotos ; ) lugar tinha uma vibração muito fria com a o fundo . A transmissão a o vivo de partida de críquete também estava acontecendo . um pouco manter uma conversa com .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in augmented_texts:\n",
    "    print(i + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Concatenar POS tags para texto\n",
    "\n",
    "As POS tags definem o papel das palavras em uma frase com base no contexto. Observe o exemplo abaixo:\n",
    "\n",
    "* Ela escreve rádio e televisão <span style = \"color: green\"> __ toca__ </span>.\n",
    "* Ele <span style = \"color: blue\"> __ joga__ </span> futebol no parque.\n",
    "\n",
    "A palavra \"brinca\" na primeira frase é um substantivo e na segunda frase é um verbo. No entanto, nosso sistema a trataria da mesma forma. Portanto, a marcação POS dessas palavras é útil. Concatenaremos as POS tags nas palavras do texto e aumentá-las-emos com a ajuda da biblioteca spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizar\n",
    "tokens_pos = []\n",
    "for token in doc:\n",
    "    tokens_pos.append(token.text+\"_\"+token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Eu_PRON', 'visitei_VERB', 'este_DET', 'lugar_NOUN', 'no_DET', 'dia_NOUN', 'dos_VERB', 'namorados_NOUN', 'à_ADP', 'noite_NOUN', '._PUNCT', 'Tivemos_VERB', 'que_SCONJ', 'esperar_VERB', 'cerca_ADV', 'de_ADP', '15_NUM', 'minutos_SYM', 'para_ADP', 'conseguir_VERB', 'uma_DET', 'mesa_NOUN', 'aqui_ADV', '._PUNCT', 'Utilizamos_VERB', 'esse_DET', 'tempo_NOUN', 'para_ADP', 'tirar_VERB', 'fotos_NOUN', ';_PUNCT', ')_PUNCT', 'Este_DET', 'lugar_NOUN', 'tinha_VERB', 'uma_DET', 'vibração_NOUN', 'muito_ADV', 'fria_ADJ', 'com_ADP', 'música_NOUN', 'alta_ADJ', 'a_ADP', 'o_DET', 'fundo_NOUN', '._PUNCT', 'A_DET', 'transmissão_NOUN', 'a_ADP', 'o_DET', 'vivo_NOUN', 'de_ADP', 'uma_DET', 'partida_NOUN', 'de_ADP', 'críquete_PROPN', 'também_ADV', 'estava_AUX', 'acontecendo_VERB', '._PUNCT', 'Foi_VERB', 'um_DET', 'pouco_DET', 'difícil_ADJ', 'manter_VERB', 'uma_DET', 'conversa_NOUN', 'com_ADP', 'alguém_PRON', '._PUNCT']\n"
     ]
    }
   ],
   "source": [
    "print(tokens_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eu_PRON visitei_VERB este_DET lugar_NOUN no_DET dia_NOUN dos_VERB namorados_NOUN à_ADP noite_NOUN ._PUNCT Tivemos_VERB que_SCONJ esperar_VERB cerca_ADV de_ADP 15_NUM minutos_SYM para_ADP conseguir_VERB uma_DET mesa_NOUN aqui_ADV ._PUNCT Utilizamos_VERB esse_DET tempo_NOUN para_ADP tirar_VERB fotos_NOUN ;_PUNCT )_PUNCT Este_DET lugar_NOUN tinha_VERB uma_DET vibração_NOUN muito_ADV fria_ADJ com_ADP música_NOUN alta_ADJ a_ADP o_DET fundo_NOUN ._PUNCT A_DET transmissão_NOUN a_ADP o_DET vivo_NOUN de_ADP uma_DET partida_NOUN de_ADP críquete_PROPN também_ADV estava_AUX acontecendo_VERB ._PUNCT Foi_VERB um_DET pouco_DET difícil_ADJ manter_VERB uma_DET conversa_NOUN com_ADP alguém_PRON ._PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\" \".join(tokens_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Substituir entidades nomeadas por suas categorias\n",
    "\n",
    "Agora veremos como podemos usar o reconhecimento de entidade nomeada para aumentar nossos dados de texto. Nesta técnica, substituiremos as entidades nomeadas por suas respectivas categorias mais amplas.\n",
    "\n",
    "Por exemplo, na frase <span style = \"color: green\"> \"A Apple está pensando em comprar uma startup no Brasil.\" </span>, a entidade __Apple__ é uma organização e __Brasil__ é uma entidade geopolítica. Substituiremos ambas as entidades pelas tags ORG e GPE, respectivamente. Portanto, a frase aumentada seria ...\n",
    "\n",
    "<span style = \"color: magenta\"> \"__ ORG__ está pensando em comprar uma startup __GPE__.\" </span>\n",
    "\n",
    "Esse tipo de aumento é adequado para as tarefas em que não estamos muito preocupados com o nome das entidades. Vamos experimentá-lo nos dados da amostra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['visitei este lugar no dia dos namorados à . Tivemos que esperar cerca 15 para conseguir uma aqui . Utilizamos esse tempo tirar fotos ) Este lugar tinha uma vibração muito fria com música alta a o fundo . A transmissão a de uma partida de críquete estava acontecendo Foi um pouco uma com alguém .', 'Eu este lugar no dos namorados à noite Tivemos que esperar cerca de 15 minutos para conseguir uma mesa aqui Utilizamos esse para tirar ) tinha uma vibração muito fria com música alta o fundo A a o vivo de partida de críquete também estava acontecendo . Foi um pouco difícil manter uma com alguém .', 'Eu visitei este lugar dia dos namorados à noite Tivemos que esperar cerca de 15 minutos para conseguir uma mesa aqui . esse tempo tirar ; Este tinha uma vibração fria com música alta a o fundo . transmissão a vivo uma partida de críquete também estava um pouco difícil manter uma conversa com alguém .', 'Eu este no dia dos namorados à . Tivemos que de minutos para conseguir uma mesa aqui . Utilizamos esse tempo para tirar ) Este lugar tinha uma muito fria com música alta o fundo . A transmissão a o de partida de críquete também estava acontecendo . Foi pouco difícil manter conversa com alguém .', 'Eu visitei este lugar dia dos namorados noite . Tivemos que esperar cerca de para conseguir uma mesa Utilizamos tempo para tirar fotos ; ) lugar tinha uma vibração muito fria com a o fundo . A transmissão a o vivo de partida de críquete também estava acontecendo . um pouco manter uma conversa com .']\n"
     ]
    }
   ],
   "source": [
    "aug_text = augmented_texts #sample_text\n",
    "for ent in doc.ents:\n",
    "    aug_text = re.sub(ent.text, ent.label_, aug_text)\n",
    "    \n",
    "print(aug_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tente as técnicas mencionadas acima para aumentar os dados usando os textos da tarefa de Text Mining ou em qualquer outro de sua preferência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
